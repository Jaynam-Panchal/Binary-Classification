{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Binary Classification Training Pipeline\n",
        "\n",
        "This notebook demonstrates the professional training pipeline with MLflow integration, advanced hyperparameter tuning, and comprehensive evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('.')\n",
        "\n",
        "from train_pipeline import BinaryClassificationTrainer\n",
        "from data_preprocessing import DataPreprocessor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the trainer with MLflow\n",
        "trainer = BinaryClassificationTrainer(\n",
        "    experiment_name=\"binary_classification_experiment\",\n",
        "    tracking_uri=\"file:./mlruns\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Preprocess Stroke Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load stroke dataset\n",
        "stroke_data_path = \"../data/stroke/Dataset1.csv\"\n",
        "X_stroke, y_stroke = trainer.preprocessor.preprocess_stroke_data(stroke_data_path)\n",
        "\n",
        "# Check class distribution\n",
        "stroke_dist = trainer.preprocessor.get_class_distribution(y_stroke)\n",
        "print(\"Stroke Dataset Class Distribution:\")\n",
        "print(f\"  Class counts: {stroke_dist['class_counts']}\")\n",
        "print(f\"  Class proportions: {stroke_dist['class_proportions']}\")\n",
        "print(f\"  Is imbalanced: {stroke_dist['is_imbalanced']}\")\n",
        "print(f\"  Total samples: {stroke_dist['total_samples']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data with SMOTE for class imbalance\n",
        "X_train_stroke, X_test_stroke, y_train_stroke, y_test_stroke = trainer.preprocessor.split_data(\n",
        "    X_stroke, y_stroke, test_size=0.2, apply_smote=True\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train_stroke)}\")\n",
        "print(f\"Test set size: {len(X_test_stroke)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Models on Stroke Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train all models on stroke dataset\n",
        "trainer.train_all_models(\n",
        "    dataset_name=\"stroke\",\n",
        "    X_train=X_train_stroke,\n",
        "    y_train=y_train_stroke,\n",
        "    X_test=X_test_stroke,\n",
        "    y_test=y_test_stroke,\n",
        "    n_iter=50  # Number of hyperparameter combinations to try\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Preprocess Hiring Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load hiring dataset\n",
        "hiring_data_path = \"../data/HIRING/Dataset2.csv\"\n",
        "X_hiring, y_hiring = trainer.preprocessor.preprocess_hiring_data(hiring_data_path)\n",
        "\n",
        "# Check class distribution\n",
        "hiring_dist = trainer.preprocessor.get_class_distribution(y_hiring)\n",
        "print(\"Hiring Dataset Class Distribution:\")\n",
        "print(f\"  Class counts: {hiring_dist['class_counts']}\")\n",
        "print(f\"  Class proportions: {hiring_dist['class_proportions']}\")\n",
        "print(f\"  Is imbalanced: {hiring_dist['is_imbalanced']}\")\n",
        "print(f\"  Total samples: {hiring_dist['total_samples']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data with SMOTE\n",
        "X_train_hiring, X_test_hiring, y_train_hiring, y_test_hiring = trainer.preprocessor.split_data(\n",
        "    X_hiring, y_hiring, test_size=0.2, apply_smote=True\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train_hiring)}\")\n",
        "print(f\"Test set size: {len(X_test_hiring)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Models on Hiring Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train all models on hiring dataset\n",
        "trainer.train_all_models(\n",
        "    dataset_name=\"hiring\",\n",
        "    X_train=X_train_hiring,\n",
        "    y_train=y_train_hiring,\n",
        "    X_test=X_test_hiring,\n",
        "    y_test=y_test_hiring,\n",
        "    n_iter=50\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare models on stroke dataset\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL COMPARISON - STROKE DATASET\")\n",
        "print(\"=\"*60)\n",
        "stroke_comparison = trainer.compare_models(\"stroke\")\n",
        "print(stroke_comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare models on hiring dataset\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL COMPARISON - HIRING DATASET\")\n",
        "print(\"=\"*60)\n",
        "hiring_comparison = trainer.compare_models(\"hiring\")\n",
        "print(hiring_comparison)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Access MLflow UI\n",
        "\n",
        "To view all experiments, metrics, and artifacts, run:\n",
        "```bash\n",
        "mlflow ui\n",
        "```\n",
        "\n",
        "Then open http://localhost:5000 in your browser."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
